{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PODCAST SUMMARIZER USING PYTHON  SCRIPT\n",
    "\n",
    "Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import openai\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing our data and reading the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker 0 (00:00:00,039-00:00:06,457): Podcast. Take it out. The Joe, Regan. Experience. Train my day, Joe Regan podcast, my day.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 1 (00:00:11,273-00:00:13,492): George,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 0 (00:00:14,959-00:00:15,399): Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker 1 (00:00:15,399-00:00:16,579): What do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaker 0 (00:00:16,878-00:00:21,456): Yeah. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaker 1 (00:00:21,916-00:00:24,455): Does it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Speaker 0 (01:57:11,752-01:57:26,583): I reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Speaker 1 (01:57:26,583-01:57:31,260): Well, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Speaker 0 (01:57:31,260-01:57:31,580): you, sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Speaker 1 (01:57:31,580-01:57:34,619): Susan. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Speaker 1 (01:57:34,619-01:57:36,359): Alright...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker 0 (00:00:00,039-00:00:06,457): Podcast. Take it out. The Joe, Regan. Experience. Train my day, Joe Regan podcast, my day.\n",
       "0     Speaker 1 (00:00:11,273-00:00:13,492): George,...                                                                               \n",
       "1     Speaker 0 (00:00:14,959-00:00:15,399): Thank you.                                                                               \n",
       "2     Speaker 1 (00:00:15,399-00:00:16,579): What do...                                                                               \n",
       "3     Speaker 0 (00:00:16,878-00:00:21,456): Yeah. L...                                                                               \n",
       "4     Speaker 1 (00:00:21,916-00:00:24,455): Does it...                                                                               \n",
       "...                                                 ...                                                                               \n",
       "1013  Speaker 0 (01:57:11,752-01:57:26,583): I reall...                                                                               \n",
       "1014  Speaker 1 (01:57:26,583-01:57:31,260): Well, G...                                                                               \n",
       "1015   Speaker 0 (01:57:31,260-01:57:31,580): you, sir.                                                                               \n",
       "1016  Speaker 1 (01:57:31,580-01:57:34,619): Susan. ...                                                                               \n",
       "1017  Speaker 1 (01:57:34,619-01:57:36,359): Alright...                                                                               \n",
       "\n",
       "[1018 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying file path\n",
    "text_data = pd.read_csv(\"116_diarized_timestamped_transcript.txt\", delimiter=\"\\t\")\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/scientist-\n",
      "[nltk_data]     ezzy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Download necessary NLTK resources if not already present\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the transcript text\n",
    "transcript = \"116_diarized_timestamped_transcript.txt\"\n",
    "\n",
    "# Tokenize the transcript into sentences\n",
    "sentences = sent_tokenize(transcript)\n",
    "\n",
    "# Create a frequency distribution of words, excluding stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_counts = FreqDist(word.lower() for sentence in sentences for word in sentence.split() if word not in stopwords)\n",
    "\n",
    "# Identify the most frequent words (excluding punctuation)\n",
    "most_frequent_words = word_counts.most_common(20)\n",
    "non_punctuation_words = [word for word, _ in most_frequent_words if not any(char.isalnum() for char in word)]\n",
    "\n",
    "# Extract candidate sentences using keyword matching\n",
    "candidate_sentences = []\n",
    "for sentence in sentences:\n",
    "    # Check if at least 2 of the most frequent words are present\n",
    "    if sum(word in sentence.lower() for word in non_punctuation_words) >= 2:\n",
    "        candidate_sentences.append(sentence)\n",
    "\n",
    "# Rank candidate sentences based on their position in the transcript (earlier sentences are considered more relevant)\n",
    "ranked_sentences = sorted(candidate_sentences, key=sentences.index)\n",
    "\n",
    "# Extract top N sentences (adjust N as needed)\n",
    "summary = \" \".join(ranked_sentences[:5])\n",
    "\n",
    "# Print the summary\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
