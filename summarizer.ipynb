{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PODCAST SUMMARIZER USING PYTHON  SCRIPT\n",
    "\n",
    "Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import openai\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing our data and reading the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker 0 (00:00:00,039-00:00:06,457): Podcast. Take it out. The Joe, Regan. Experience. Train my day, Joe Regan podcast, my day.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 1 (00:00:11,273-00:00:13,492): George,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 0 (00:00:14,959-00:00:15,399): Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker 1 (00:00:15,399-00:00:16,579): What do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaker 0 (00:00:16,878-00:00:21,456): Yeah. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaker 1 (00:00:21,916-00:00:24,455): Does it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Speaker 0 (01:57:11,752-01:57:26,583): I reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Speaker 1 (01:57:26,583-01:57:31,260): Well, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Speaker 0 (01:57:31,260-01:57:31,580): you, sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Speaker 1 (01:57:31,580-01:57:34,619): Susan. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Speaker 1 (01:57:34,619-01:57:36,359): Alright...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker 0 (00:00:00,039-00:00:06,457): Podcast. Take it out. The Joe, Regan. Experience. Train my day, Joe Regan podcast, my day.\n",
       "0     Speaker 1 (00:00:11,273-00:00:13,492): George,...                                                                               \n",
       "1     Speaker 0 (00:00:14,959-00:00:15,399): Thank you.                                                                               \n",
       "2     Speaker 1 (00:00:15,399-00:00:16,579): What do...                                                                               \n",
       "3     Speaker 0 (00:00:16,878-00:00:21,456): Yeah. L...                                                                               \n",
       "4     Speaker 1 (00:00:21,916-00:00:24,455): Does it...                                                                               \n",
       "...                                                 ...                                                                               \n",
       "1013  Speaker 0 (01:57:11,752-01:57:26,583): I reall...                                                                               \n",
       "1014  Speaker 1 (01:57:26,583-01:57:31,260): Well, G...                                                                               \n",
       "1015   Speaker 0 (01:57:31,260-01:57:31,580): you, sir.                                                                               \n",
       "1016  Speaker 1 (01:57:31,580-01:57:34,619): Susan. ...                                                                               \n",
       "1017  Speaker 1 (01:57:34,619-01:57:36,359): Alright...                                                                               \n",
       "\n",
       "[1018 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying file path\n",
    "text_data = pd.read_csv(\"116_diarized_timestamped_transcript.txt\", delimiter=\"\\t\")\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/scientist-\n",
      "[nltk_data]     ezzy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '116_diarized_timestamped_transcript.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m transcript_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m116_diarized_timestamped_transcript.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Open the transcript file and read its content\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtranscript_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Tokenize the transcript into sentences\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ezra/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '116_diarized_timestamped_transcript.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download necessary NLTK resources if not already present\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the transcript file path\n",
    "transcript_file_path = \"116_diarized_timestamped_transcript.txt\"\n",
    "\n",
    "# Open the transcript file and read its content\n",
    "with open(transcript_file_path, \"r\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "# Tokenize the transcript into sentences\n",
    "sentences = sent_tokenize(transcript)\n",
    "\n",
    "# Tokenize the transcript into sentences\n",
    "sentences = sent_tokenize(transcript)\n",
    "\n",
    "# Define topic detection function based on sentence starting with \"Speaker\"\n",
    "def detect_topic(sentence):\n",
    "    if sentence.startswith(\"Speaker\"):\n",
    "        _, topic = sentence.split(\":\", 1)\n",
    "        return topic.strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to summarize by topic\n",
    "def summarize_by_topic(sentences):\n",
    "    summary = \"\"\n",
    "    current_topic = None\n",
    "    topic_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Detect topic change\n",
    "        new_topic = detect_topic(sentence)\n",
    "        if new_topic:\n",
    "            # Save previous topic summary and start a new one\n",
    "            if current_topic:\n",
    "                summary += f\"\\n**{current_topic}** (00:00:00,000-00:00:00,000):\\n{''.join(topic_sentences)}\"\n",
    "            current_topic = new_topic\n",
    "            topic_sentences = []\n",
    "        # Add sentence to the current topic\n",
    "        topic_sentences.append(sentence)\n",
    "    # Add the last topic summary\n",
    "    if current_topic:\n",
    "        summary += f\"\\n**{current_topic}** (00:00:00,000-00:00:00,000):\\n{''.join(topic_sentences)}\"\n",
    "    return summary\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarize_by_topic(sentences)\n",
    "\n",
    "# Write the summary to a text file\n",
    "with open(\"summarized_text.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Summary written to summarized_text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
